<!DOCTYPE html>
<html lang="en">
<head>

  <meta charset="utf-8" />

  
  <title>Pythia: AI Assisted Code Completion System</title>

  
  
  <link href="//cdn.jsdelivr.net" rel="dns-prefetch">
  <link href="//cdnjs.cloudflare.com" rel="dns-prefetch">
  
  <link href="//at.alicdn.com" rel="dns-prefetch">
  
  <link href="//fonts.googleapis.com" rel="dns-prefetch">
  <link href="//fonts.gstatic.com" rel="dns-prefetch">
  
  
  
  
  

  

  
  <meta name="author" content="Haobo Gu">
  <meta name="description" content="Note taking &amp; archiving">

  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:site" content="@gohugoio">
  <meta name="twitter:title" content="Haobo&#39;s Blog">
  <meta name="twitter:description" content="Note taking &amp; archiving">
  <meta name="twitter:image" content="/images/avatar.png">

  
  <meta property="og:type" content="website">
  <meta property="og:title" content="Haobo&#39;s Blog">
  <meta property="og:description" content="Note taking &amp; archiving">
  <meta property="og:url" content="https://haobogu.github.io/posts/pythia-ai-assisted-code-completion-system/">
  <meta property="og:image" content="/images/avatar.png">




<meta name="generator" content="Hugo 0.59.1" />


<link rel="canonical" href="https://haobogu.github.io/posts/pythia-ai-assisted-code-completion-system/">

<meta name="renderer" content="webkit">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="format-detection" content="telephone=no,email=no,adress=no">
<meta http-equiv="Cache-Control" content="no-transform">


<meta name="robots" content="index,follow">
<meta name="referrer" content="origin-when-cross-origin">







<meta name="theme-color" content="#02b875">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black">
<meta name="apple-mobile-web-app-title" content="Haobo&#39;s Blog">
<meta name="msapplication-tooltip" content="Haobo&#39;s Blog">
<meta name='msapplication-navbutton-color' content="#02b875">
<meta name="msapplication-TileColor" content="#02b875">
<meta name="msapplication-TileImage" content="/icons/icon-144x144.png">
<link rel="icon" href="https://haobogu.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://haobogu.github.io/icons/icon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://haobogu.github.io/icons/icon-32x32.png">
<link rel="icon" sizes="192x192" href="https://haobogu.github.io/icons/icon-192x192.png">
<link rel="apple-touch-icon" href="https://haobogu.github.io/icons/icon-152x152.png">
<link rel="manifest" href="https://haobogu.github.io/manifest.json">


<link rel="preload" href="https://haobogu.github.io/styles/main-rendered.min.css" as="style">

<link rel="preload" href="https://haobogu.github.io/styles/custom.min.css" as="style">
<link rel="preload" href="https://fonts.googleapis.com/css?family=Lobster" as="style">
<link rel="preload" href="https://haobogu.github.io/images/avatar.png" as="image">
<link rel="preload" href="https://haobogu.github.io/images/grey-prism.svg" as="image">


<style>
  body {
    background: rgb(244, 243, 241) url('/images/grey-prism.svg') repeat fixed;
  }
</style>
<link rel="stylesheet" href="https://haobogu.github.io/styles/main-rendered.min.css">

<link rel="stylesheet" href="https://haobogu.github.io/styles/custom.min.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lobster">







<script type="text/javascript"
        async
        src="https://cdn.bootcss.com/mathjax/2.7.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[\[','\]\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js", "AMSfont.js"] }
  }
});

MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<style>
code.has-jax {
    font: inherit;
    font-size: 100%;
    background: inherit;
    border: inherit;
    color: #515151;
}
</style>



  
  
<!--[if lte IE 8]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/videojs-ie8@1.1.2/dist/videojs-ie8.min.js"></script>
<![endif]-->

<!--[if lte IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/eligrey-classlist-js-polyfill@1.2.20180112/classList.min.js"></script>
<![endif]-->


</head>
  <body>
    <div class="suspension">
      <a role="button" aria-label="Go to top" title="Go to top" class="to-top is-hide"><span class="icon icon-up" aria-hidden="true"></span></a>
      
    </div>
    
    
  <header class="site-header">
  <a href="https://haobogu.github.io"><img class="avatar" src="https://haobogu.github.io/images/avatar.png" alt="Avatar"></a>
  
  <h2 class="title"><a href="https://haobogu.github.io">Haobo&#39;s Blog</a></h2>
  
  <p class="subtitle">Notes &amp; Thoughts</p>
  <button class="menu-toggle" type="button" aria-label="Main Menu" aria-expanded="false" tab-index="0">
    <span class="icon icon-menu" aria-hidden="true"></span>
  </button>

  <nav class="site-menu collapsed">
    <h2 class="offscreen">Main Menu</h2>
    <ul class="menu-list">
      
      
      
      
        <li class="menu-item
          
          
          ">
          <a href="https://haobogu.github.io/">Home</a>
        </li>
      
        <li class="menu-item
          
          
          ">
          <a href="https://haobogu.github.io/posts/">Posts</a>
        </li>
      
        <li class="menu-item
          
          
          ">
          <a href="https://haobogu.github.io/tags/">Tags</a>
        </li>
      
        <li class="menu-item
          
          
          ">
          <a href="https://haobogu.github.io/about/">About</a>
        </li>
      
    </ul>
  </nav>
  <nav class="social-menu collapsed">
    <h2 class="offscreen">Social Networks</h2>
    <ul class="social-list"><li class="social-item">
          <a href="mailto:haobogu@outlook.com" title="Email" aria-label="Email">
            <span class="icon icon-email" aria-hidden="true"></span>
          </a>
        </li><li class="social-item">
          <a href="//github.com/HaoboGu" rel="me" title="GitHub" aria-label="GitHub">
	    <span class="icon icon-github" aria-hidden="true"></span>
          </a>
        </li><li class="social-item">
          <a href="//www.linkedin.com/in/%e6%b5%a9%e6%b3%a2-%e9%a1%be-a71875126" rel="me" title="LinkedIn" aria-label="LinkedIn">
            <span class="icon icon-linkedin" aria-hidden="true"></span>
          </a>
        </li><li class="social-item">
          <a href="//space.bilibili.com/26705509" rel="me" title="Bilibili" aria-label="Bilibili">
            <span class="icon icon-bilibili" aria-hidden="true"></span>
          </a>
        </li></ul>
  </nav>
</header>

       
         <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Fira&#43;Code%7cFira&#43;Mono%7cRoboto&#43;Mono%7cSource&#43;Sans&#43;Pro%7cSource&#43;Serif&#43;Pro&amp;display=swap" type="text/css" media="all" />
     
  <section class="main post-detail">
    <header class="post-header">
      <h1 class="post-title">Pythia: AI Assisted Code Completion System</h1>
      <p class="post-meta">@Haobo Gu · Sep 4, 2019 · 3 min read</p>
    </header>
    <article class="post-content">
        

<p>Paper link: <a href="https://www.kdd.org/kdd2019/accepted-papers/view/pythia-ai-assisted-code-completion-system">https://www.kdd.org/kdd2019/accepted-papers/view/pythia-ai-assisted-code-completion-system</a></p>

<h2 id="abstract">Abstract</h2>

<p>This paper proposes an end-to-end code completion approach call Pythia, which has been deployed as part of Intellicode extension in Visual Studio Code. Pythia is trained on 2700+ Python open source software GitHub repositories and achieves SOTA performance. Pythia uses LSTM to learn the long distance dependencies in code context sequences, which is extracted using in-order depth-first AST traversal. The parameter tuning and deployment related issues are also discussed in the later parts of the paper.</p>

<h2 id="dataset">Dataset</h2>

<p>The authors collected 2700 top-starred Github Python projects in various domains. The dataset contains over 15.8 million <strong>method calls</strong>. The following is the most method call occurrences:</p>

<p><img src="http://haobo-markdown.oss-cn-zhangjiakou.aliyuncs.com/markdown/2019-09-04-024648.png" alt="image-20190904104648313" /></p>

<p>The dataset is divided to development set and test set with a 70-30 ratio on the repo level. Then the development set is split into training and validation sets in the proportion 80-20.</p>

<p>The online model is trained using the entire dataset.</p>

<h2 id="code-representations">Code Representations</h2>

<p>The Pythia exploits the partial AST which is derived from code snippets containing method calls and member access expression. The ASTs are serialized to token sequence using <strong>in-order depth-first traversal</strong>. When extracting training sequence, for each method call, <strong><em>T</em></strong> preceding tokens are used, where T is a tunable parameter.</p>

<p>Further, the AST token sequence must be converted to numeric vector to be consumed by LSTM. Word2Vec is used to train the embedding of tokens.</p>

<h3 id="embedding-training">Embedding  training</h3>

<p>All tokens are mapped to integers from 1 to V, while the infrequent tokens are removed in order to reduce the vocabulary size. During training, OOVs are mapped to an integer greater than V. <code>.</code> is used as the EOS character.</p>

<p>Method names are one-hot encoded as the labels. The task is to predict method names using given code snippets. All tokens are mapped to low-dimentsional vectors with semantic relationships preserved.</p>

<h3 id="tricks">Tricks</h3>

<ol>
<li>The type of variables is inferred using static analysis methods</li>
<li>Import alias is ignored</li>
<li>Variable names are normalized to <code>var:&lt;variable type&gt;</code> format</li>
</ol>

<h2 id="nerual-code-completion-model">Nerual Code Completion Model</h2>

<p>LSTM is used to predict completion.</p>

<p><img src="http://haobo-markdown.oss-cn-zhangjiakou.aliyuncs.com/markdown/2019-09-04-033911.png" alt="image-20190904113911307" /></p>

<p>The input embedding matrix is reused as the output classification matrix to reduce the number of parameters. Hence, the fully connected layer in before the output is no longer needed.</p>

<h3 id="model-training">Model Training</h3>

<p>Parallel backpropagation through time algorithm with adam optimizer and mini-batch is used to train the LSTM. In the training, the sequences are split into three buckets by sequence lengths. In each bucket, the lengths of sequences are padded to the maximum sequence length in this bucket.</p>

<p><img src="http://haobo-markdown.oss-cn-zhangjiakou.aliyuncs.com/markdown/2019-09-04-063553.png" alt="image-20190904143553065" /></p>

<p>As for the learning rate, the authors scale the learning rate up proportionally to the number of works during the first 4 epochs:</p>

<p><img src="http://haobo-markdown.oss-cn-zhangjiakou.aliyuncs.com/markdown/2019-09-04-065128.png" alt="image-20190904145128559" /></p>

<h2 id="model-evaluation">Model Evaluation</h2>

<p><img src="http://haobo-markdown.oss-cn-zhangjiakou.aliyuncs.com/markdown/2019-09-04-065731.png" alt="image-20190904145730931" /></p>

<p><img src="http://haobo-markdown.oss-cn-zhangjiakou.aliyuncs.com/markdown/2019-09-04-065716.png" alt="image-20190904145716624" /></p>

<h2 id="model-deployment">Model Deployment</h2>

<p>To deploy the model to lightweight client devices, the <strong>neural network quantization</strong> method is used to reduce the number of stored weights. The original Pythia model is trained in IEEE 754 numeric format, which is based on 32-bit float. The numeric format of published model is quantized into 8-bit unsigned integer. For Pythia, the model size is reduced from 152MB to 38MB with quantization. The top-5 accuracy is reduced from 92% to 89%.</p>

    </article>
    <footer class="post-footer">
      
      <ul class="post-tags">
        
          <li><a href="https://haobogu.github.io/tags/paper-note"><span class="tag">Paper-Note</span></a></li>
        
          <li><a href="https://haobogu.github.io/tags/code-completion"><span class="tag">Code-Completion</span></a></li>
        
      </ul>
      
      <p class="post-copyright">
        
      </p>
    </footer>
    
      
    
  </section>
  
<footer class="site-footer">
  <p>© 2017-2019 Haobo&#39;s Blog</p>
  <p>Powered by <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> with theme <a href="https://github.com/laozhu/hugo-nuo" target="_blank" rel="noopener">Nuo</a>.</p>
  
</footer>


<script src="https://cdn.jsdelivr.net/npm/smooth-scroll@15.0.0/dist/smooth-scroll.min.js"></script>








<script src="https://haobogu.github.io/scripts/index.min.js"></script>

<script>
  if ('serviceWorker' in navigator) {
    navigator.serviceWorker.register('\/service-worker.js').then(function() {
      console.log('[ServiceWorker] Registered');
    });
  }
</script>








  </body>
</html>
